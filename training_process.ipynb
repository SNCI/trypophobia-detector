{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This neural network detects trypophobic structures in images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This file contains the training process of a network which obtained 88.44% accuracy on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "#Importing the necesary modules\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.optimizers import SGD, Adagrad, Adadelta\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalMaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Some configuration variables\n",
    "fobia_folder = \"./trypophobic/\"\n",
    "normal_folder = \"./data_train/reddit_sub_pics/\"\n",
    "final_weights_path = \"trypophobia_weights.h5\"\n",
    "resolution_x = 224\n",
    "resolution_y = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1560 images belonging to 2 classes.\n",
      "Found 320 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Creation of generators for extracting the bottleneck features of the pretrained vgg16 network\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   dim_ordering='th',\n",
    "                                  zca_whitening=False, featurewise_center=False, featurewise_std_normalization=False)\n",
    "train_data_generator = train_datagen.flow_from_directory('dane/data_train/',\n",
    "                                            target_size=(resolution_x, resolution_y),\n",
    "                                            batch_size=8,\n",
    "                                            class_mode=\"categorical\",\n",
    "                                            shuffle = False,\n",
    "                                            classes=['non-trypophobic','trypophobic'])\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255, dim_ordering='th',\n",
    "                                 zca_whitening=False, featurewise_center=False, featurewise_std_normalization=False)\n",
    "test_data_generator = test_datagen.flow_from_directory('dane/data_valid/',\n",
    "                                            target_size=(resolution_x, resolution_y),\n",
    "                                            batch_size=8,\n",
    "                                            class_mode=\"categorical\",\n",
    "                                            shuffle = False,\n",
    "                                            classes=['non-trypophobic','trypophobic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Define a function returning a pretrained vgg16 network containing a given number of convolution blocks\n",
    "def VGG_16(weights_path=None, num_of_conv_blocks = 1):\n",
    "    \n",
    "    model = Sequential()\n",
    "    i = 0\n",
    "    while(True):\n",
    "        model.add(ZeroPadding2D((1,1),input_shape=(3,224,224)))\n",
    "        model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "        model.add(ZeroPadding2D((1,1)))\n",
    "        model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "        model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "        \n",
    "        i+=1\n",
    "        if(i == num_of_conv_blocks):\n",
    "            break\n",
    "        \n",
    "        model.add(ZeroPadding2D((1,1)))\n",
    "        model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "        model.add(ZeroPadding2D((1,1)))\n",
    "        model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "        model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "        \n",
    "        i+=1\n",
    "        if(i == num_of_conv_blocks):\n",
    "            break\n",
    "\n",
    "        model.add(ZeroPadding2D((1,1)))\n",
    "        model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "        model.add(ZeroPadding2D((1,1)))\n",
    "        model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "        model.add(ZeroPadding2D((1,1)))\n",
    "        model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "        model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "        \n",
    "        i+=1\n",
    "        if(i == num_of_conv_blocks):\n",
    "            break\n",
    "\n",
    "        model.add(ZeroPadding2D((1,1)))\n",
    "        model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "        model.add(ZeroPadding2D((1,1)))\n",
    "        model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "        model.add(ZeroPadding2D((1,1)))\n",
    "        model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "        model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "        \n",
    "        i+=1\n",
    "        if(i == num_of_conv_blocks):\n",
    "            break\n",
    "\n",
    "        model.add(ZeroPadding2D((1,1)))\n",
    "        model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "        model.add(ZeroPadding2D((1,1)))\n",
    "        model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "        model.add(ZeroPadding2D((1,1)))\n",
    "        model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "        model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "        \n",
    "        break\n",
    "\n",
    "    f = h5py.File(weights_path)\n",
    "    for k in range(f.attrs['nb_layers']):\n",
    "        if k >= len(model.layers):\n",
    "            # we don't look at the last (fully-connected) layers in the savefile\n",
    "            break\n",
    "        g = f['layer_{}'.format(k)]\n",
    "        weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]\n",
    "        model.layers[k].set_weights(weights)\n",
    "        model.layers[k].trainable = False\n",
    "    f.close()\n",
    "    print('Model loaded.')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n",
      "      OPERATION           DATA DIMENSIONS   WEIGHTS(N)   WEIGHTS(%)\n",
      "\n",
      "          Input   #####   (3, 224, 224)\n",
      "  ZeroPadding2D   \\|||/ -------------------         0     0.0%\n",
      "                  #####   (3, 226, 226)\n",
      "  Convolution2D    \\|/  -------------------      1792     0.0%\n",
      "           relu   #####   (64, 224, 224)\n",
      "  ZeroPadding2D   \\|||/ -------------------         0     0.0%\n",
      "                  #####   (64, 226, 226)\n",
      "  Convolution2D    \\|/  -------------------     36928     0.3%\n",
      "           relu   #####   (64, 224, 224)\n",
      "   MaxPooling2D   YYYYY -------------------         0     0.0%\n",
      "                  #####   (64, 112, 112)\n",
      "  ZeroPadding2D   \\|||/ -------------------         0     0.0%\n",
      "                  #####   (64, 114, 114)\n",
      "  Convolution2D    \\|/  -------------------     73856     0.5%\n",
      "           relu   #####   (128, 112, 112)\n",
      "  ZeroPadding2D   \\|||/ -------------------         0     0.0%\n",
      "                  #####   (128, 114, 114)\n",
      "  Convolution2D    \\|/  -------------------    147584     1.0%\n",
      "           relu   #####   (128, 112, 112)\n",
      "   MaxPooling2D   YYYYY -------------------         0     0.0%\n",
      "                  #####   (128, 56, 56)\n",
      "  ZeroPadding2D   \\|||/ -------------------         0     0.0%\n",
      "                  #####   (128, 58, 58)\n",
      "  Convolution2D    \\|/  -------------------    295168     2.0%\n",
      "           relu   #####   (256, 56, 56)\n",
      "  ZeroPadding2D   \\|||/ -------------------         0     0.0%\n",
      "                  #####   (256, 58, 58)\n",
      "  Convolution2D    \\|/  -------------------    590080     4.0%\n",
      "           relu   #####   (256, 56, 56)\n",
      "  ZeroPadding2D   \\|||/ -------------------         0     0.0%\n",
      "                  #####   (256, 58, 58)\n",
      "  Convolution2D    \\|/  -------------------    590080     4.0%\n",
      "           relu   #####   (256, 56, 56)\n",
      "   MaxPooling2D   YYYYY -------------------         0     0.0%\n",
      "                  #####   (256, 28, 28)\n",
      "  ZeroPadding2D   \\|||/ -------------------         0     0.0%\n",
      "                  #####   (256, 30, 30)\n",
      "  Convolution2D    \\|/  -------------------   1180160     8.0%\n",
      "           relu   #####   (512, 28, 28)\n",
      "  ZeroPadding2D   \\|||/ -------------------         0     0.0%\n",
      "                  #####   (512, 30, 30)\n",
      "  Convolution2D    \\|/  -------------------   2359808    16.0%\n",
      "           relu   #####   (512, 28, 28)\n",
      "  ZeroPadding2D   \\|||/ -------------------         0     0.0%\n",
      "                  #####   (512, 30, 30)\n",
      "  Convolution2D    \\|/  -------------------   2359808    16.0%\n",
      "           relu   #####   (512, 28, 28)\n",
      "   MaxPooling2D   YYYYY -------------------         0     0.0%\n",
      "                  #####   (512, 14, 14)\n",
      "  ZeroPadding2D   \\|||/ -------------------         0     0.0%\n",
      "                  #####   (512, 16, 16)\n",
      "  Convolution2D    \\|/  -------------------   2359808    16.0%\n",
      "           relu   #####   (512, 14, 14)\n",
      "  ZeroPadding2D   \\|||/ -------------------         0     0.0%\n",
      "                  #####   (512, 16, 16)\n",
      "  Convolution2D    \\|/  -------------------   2359808    16.0%\n",
      "           relu   #####   (512, 14, 14)\n",
      "  ZeroPadding2D   \\|||/ -------------------         0     0.0%\n",
      "                  #####   (512, 16, 16)\n",
      "  Convolution2D    \\|/  -------------------   2359808    16.0%\n",
      "           relu   #####   (512, 14, 14)\n",
      "   MaxPooling2D   YYYYY -------------------         0     0.0%\n",
      "                  #####   (512, 7, 7)\n"
     ]
    }
   ],
   "source": [
    "#Get the pre-trained vgg model\n",
    "vgg_model = VGG_16('vgg16_weights.h5', 5)\n",
    "\n",
    "#Visualize the network\n",
    "from keras_sequential_ascii import sequential_model_to_ascii_printout\n",
    "sequential_model_to_ascii_printout(vgg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define a helper function for generating predictions with addition of a progress bar\n",
    "def predict_generator_status(model, generator, number):\n",
    "    res = []\n",
    "    labels = []\n",
    "    num = 0\n",
    "    for batch_X, batch_Y in tqdm(generator):\n",
    "        batch_res = model.predict_on_batch(batch_X)\n",
    "        for prediction in batch_res:\n",
    "            res.append(prediction)\n",
    "        for label in batch_Y:\n",
    "            labels.append(label)\n",
    "        num+=generator.batch_size\n",
    "        \n",
    "        if num >= number:\n",
    "            break\n",
    "    return np.array(res), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate the bottleneck features of the pretrained vgg model\n",
    "# if we trained the network before then load the data from the hard drive\n",
    "bottleneck_features_train = None\n",
    "train_labels = None\n",
    "bottleneck_features_validation = None\n",
    "validation_labels = None\n",
    "\n",
    "if os.path.isfile(\"dane/bottleneck_features_train.npy\"):\n",
    "    bottleneck_features_train = np.load(open('dane/bottleneck_features_train.npy', 'rb'))\n",
    "    train_labels = np.load(open('dane/bottleneck_features_train_labels.npy', 'rb'))\n",
    "    bottleneck_features_validation = np.load(open('dane/bottleneck_features_validation.npy', 'rb'))\n",
    "    validation_labels = np.load(open('dane/bottleneck_features_validataion_labels.npy', 'rb'))\n",
    "else:    \n",
    "    bottleneck_features_train, train_labels = predict_generator_status(vgg_model, train_data_generator, 1560)\n",
    "    np.save(open('dane/bottleneck_features_train.npy', 'wb'), bottleneck_features_train)\n",
    "    np.save(open('dane/bottleneck_features_train_labels.npy', 'wb'), train_labels)\n",
    "\n",
    "    bottleneck_features_validation, validation_labels = predict_generator_status(vgg_model, test_data_generator, 320)\n",
    "    np.save(open('dane/bottleneck_features_validation.npy', 'wb'), bottleneck_features_validation)\n",
    "    np.save(open('dane/bottleneck_features_validataion_labels.npy', 'wb'), validation_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now that we have extracted the bottleneck features we can train a dense network which will be attached to the pretrained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "untrained = False\n",
    "top_model = None\n",
    "if untrained or not os.path.isfile('bottleneck_fc_model.h5'):\n",
    "    top_model = Sequential()\n",
    "    top_model.add(Flatten(input_shape=bottleneck_features_train.shape[1:]))\n",
    "    top_model.add(Dense(512, activation='relu'))\n",
    "    top_model.add(Dropout(0.5))\n",
    "    top_model.add(Dense(100, activation='relu'))\n",
    "    top_model.add(Dropout(0.5))\n",
    "    top_model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    top_model.compile(\"adam\",\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = top_model.fit(bottleneck_features_train, train_labels,\n",
    "              nb_epoch=10, batch_size=8,\n",
    "              validation_data=(bottleneck_features_validation, validation_labels), verbose=2,\n",
    "                callbacks=[ModelCheckpoint(save_best_only=True, filepath=\"dane/top_vgg16_4_weights.{epoch:02d}-{val_loss:.2f}.hdf5\")])\n",
    "    top_model.save('bottleneck_fc_model.h5')\n",
    "else:\n",
    "    top_model = load_model('bottleneck_fc_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now Fine-Tune the resulting network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#unlock the last conv layer\n",
    "for layer in vgg_model.layers[-5:-1]:\n",
    "    layer.trainable = True\n",
    "#add the bottom layer\n",
    "vgg_model.add(top_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1560 images belonging to 2 classes.\n",
      "Found 320 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#new generators for fine-tuning vgg16\n",
    "train_datagen_vgg = ImageDataGenerator(rescale=1./255, rotation_range=20, horizontal_flip=True, \n",
    "                                   dim_ordering='th',\n",
    "                                  zca_whitening=False, featurewise_center=False, featurewise_std_normalization=False)\n",
    "train_data_generator_vgg = train_datagen.flow_from_directory('dane/data_train/',\n",
    "                                            target_size=(resolution_x, resolution_y),\n",
    "                                            batch_size=8,\n",
    "                                            class_mode=\"categorical\",\n",
    "                                            shuffle = True,\n",
    "                                            classes=['non-trypophobic','trypophobic'])\n",
    "\n",
    "test_datagen_vgg = ImageDataGenerator(rescale=1./255, dim_ordering='th',\n",
    "                                 zca_whitening=False, featurewise_center=False, featurewise_std_normalization=False)\n",
    "test_data_generator_vgg = test_datagen.flow_from_directory('dane/data_valid/',\n",
    "                                            target_size=(resolution_x, resolution_y),\n",
    "                                            batch_size=8,\n",
    "                                            class_mode=\"categorical\",\n",
    "                                            shuffle = True,\n",
    "                                            classes=['non-trypophobic','trypophobic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train the resulting network using a very small learning rate\n",
    "#if we trained it before load it from the hard drive\n",
    "if not os.path.isfile(final_weights_path):\n",
    "    vgg_model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=SGD(lr=1e-5, momentum=0.9),\n",
    "                  metrics=['accuracy'])\n",
    "    vgg_model.fit_generator(nb_val_samples=320, samples_per_epoch=1560, nb_epoch=2,\n",
    "                        generator=train_data_generator_vgg,\n",
    "                        validation_data=test_data_generator_vgg)\n",
    "    vgg_model.save_weights(final_weights_path)\n",
    "else:\n",
    "    vgg_model.load_weights(final_weights_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now that we got the model ready let's check the obtained accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_cor = 0\n",
    "num_total = 0\n",
    "\n",
    "failed_images_try = []\n",
    "failed_images_norm = []\n",
    "\n",
    "for batch_X, batch_Y in tqdm(test_data_generator_vgg):\n",
    "    pre_Y = vgg_model.predict_on_batch(batch_X)\n",
    "    i = 0\n",
    "    for a,b in zip(pre_Y, batch_Y):\n",
    "        if (a[0]>a[1] and b[0]==1 ) or (a[0]<=a[1] and b[1]==1 ):\n",
    "            num_cor+=1\n",
    "        else:\n",
    "            if b[1]==1:\n",
    "                failed_images_try.append(batch_X[i])\n",
    "            else:\n",
    "                failed_images_norm.append(batch_X[i])\n",
    "        num_total+=1\n",
    "        i+=1\n",
    "    if(num_total >= 320):\n",
    "        break\n",
    "print (\"Accuracy %.02f\"%(float(num_cor)/num_total*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's see where it failed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# These images were predicted to be trypophobic but were normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, img in enumerate(failed_images_norm):\n",
    "    plt.grid(False)\n",
    "    plt.imshow(np.rollaxis(np.rollaxis(img, -1),-1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# These images were predicted to be normal but were trypophobic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, img in enumerate(failed_images_try):\n",
    "    plt.grid(False)\n",
    "    plt.imshow(np.rollaxis(np.rollaxis(img, -1),-1))\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
